## ğŸ”¥ æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰é—®é¢˜åˆ†æä¸ä¿®å¤

### ğŸ“Š æ˜¾å­˜å ç”¨è®¡ç®—

#### å•ä¸ªæ¨¡å‹æ˜¾å­˜ï¼ˆ5x5æ£‹ç›˜ï¼‰
```
æ¨¡å‹é…ç½®ï¼š
- num_filters: 128
- num_res_blocks: 8  
- num_heads: 8

å•ä¸ªæ¨¡å‹å¤§å°ï¼šçº¦ 200MB
```

#### è‡ªæˆ‘å¯¹å¼ˆæ˜¾å­˜å ç”¨
```
è‡ªæˆ‘å¯¹å¼ˆ: 10ä¸ªè¿›ç¨‹ Ã— 1ä¸ªæ¨¡å‹ = 10ä¸ªæ¨¡å‹
æ˜¾å­˜å ç”¨: 10 Ã— 200MB = 2GB
```

#### Arena æ˜¾å­˜å ç”¨ï¼ˆåŸé…ç½®ï¼‰
```
Arena: 4ä¸ªè¿›ç¨‹ Ã— 2ä¸ªæ¨¡å‹ = 8ä¸ªæ¨¡å‹
æ˜¾å­˜å ç”¨: 8 Ã— 200MB = 1.6GB
```

#### æ€»æ˜¾å­˜éœ€æ±‚
```
è‡ªæˆ‘å¯¹å¼ˆ + Arenaï¼ˆå¦‚æœåŒæ—¶å­˜åœ¨ï¼‰:
2GB + 1.6GB = 3.6GB

ä½†å®é™…ä¸Šè¿˜æœ‰ï¼š
- ä¸»è¿›ç¨‹çš„ self.nnet å’Œ self.best_nnet: 2 Ã— 200MB = 400MB
- è®­ç»ƒæ—¶çš„æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€: ~500MB
- PyTorch ç¼“å­˜: ~500MB

æ€»è®¡: çº¦ 5GB
```

### âŒ ä¸ºä»€ä¹ˆæµ‹è¯•æ²¡é—®é¢˜ï¼Œè®­ç»ƒå‡ºé”™ï¼Ÿ

#### æµ‹è¯•ç¯å¢ƒ
- åªè¿è¡Œ Arena
- Arena: 4è¿›ç¨‹ Ã— 2æ¨¡å‹ = 8ä¸ªæ¨¡å‹ = 1.6GB
- âœ… æ˜¾å­˜å……è¶³

#### è®­ç»ƒç¯å¢ƒ  
- åˆšå®Œæˆè‡ªæˆ‘å¯¹å¼ˆï¼ˆå¯èƒ½æœ‰æ®‹ç•™æ˜¾å­˜ï¼‰
- åˆšå®Œæˆè®­ç»ƒï¼ˆæ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€æœªé‡Šæ”¾ï¼‰
- ç„¶åè¿›å…¥ Arena
- ä¸»è¿›ç¨‹è¿˜æœ‰ 2 ä¸ªæ¨¡å‹å¸¸é©»
- âŒ æ˜¾å­˜ä¸è¶³ï¼

### âœ… å·²å®æ–½çš„ä¿®å¤

#### 1. å‡å°‘ Arena è¿›ç¨‹æ•°
```python
# ä» 4 å‡å°‘åˆ° 2
'arena_num_workers': 2  # 2è¿›ç¨‹ Ã— 2æ¨¡å‹ = 4ä¸ªæ¨¡å‹ = 800MB
```

#### 2. è‡ªæˆ‘å¯¹å¼ˆåæ¸…ç†æ˜¾å­˜
```python
# coach_alphazero.py
# è‡ªæˆ‘å¯¹å¼ˆå
if self.args.get('cuda', False) and torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
```

#### 3. Arena å‰æ¸…ç†æ˜¾å­˜
```python
# Arena å‰
if self.args.get('cuda', False) and torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
```

#### 4. Arena åæ¸…ç†æ˜¾å­˜
```python
# Arena å
del arena
if self.args.get('cuda', False) and torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
```

#### 5. å­è¿›ç¨‹ç»“æŸæ—¶æ¸…ç†
```python
# _execute_episode_worker å’Œ _arena_single_game_worker
del nnet, mcts, ...
if args.get('cuda', False) and torch.cuda.is_available():
    torch.cuda.empty_cache()
```

### ğŸ“Š ä¿®å¤åçš„æ˜¾å­˜å ç”¨

```
å³°å€¼æ˜¾å­˜ï¼ˆArenaé˜¶æ®µï¼‰:
- ä¸»è¿›ç¨‹: 2ä¸ªæ¨¡å‹ = 400MB
- Arena: 2è¿›ç¨‹ Ã— 2æ¨¡å‹ = 800MB
- PyTorchç¼“å­˜: ~500MB
æ€»è®¡: ~1.7GB

ç›¸æ¯”åŸæ¥çš„ 5GBï¼Œé™ä½äº† 66%ï¼
```

### ğŸ¯ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

#### å¦‚æœä»ç„¶ OOM

1. **å‡å°‘è¿›ç¨‹æ•°åˆ° 1**
   ```python
   'arena_num_workers': 1  # æœ€ä¿å®ˆ
   ```

2. **å‡å°æ¨¡å‹**
   ```python
   'num_filters': 64,      # ä» 128 é™åˆ° 64
   'num_res_blocks': 4,    # ä» 8 é™åˆ° 4
   ```

3. **ä½¿ç”¨ CPU Arena**ï¼ˆæœ€åæ‰‹æ®µï¼‰
   ```python
   'arena_mode': 'multiprocess',  # CPUå¤šè¿›ç¨‹
   'cuda': False,  # Arenaä¸ç”¨GPU
   ```

4. **å‡å°‘è‡ªæˆ‘å¯¹å¼ˆè¿›ç¨‹æ•°**
   ```python
   'num_workers': 5,  # ä» 10 é™åˆ° 5
   ```

### ğŸ“ æ˜¾å­˜ç›‘æ§å‘½ä»¤

```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
nvidia-smi --query-gpu=memory.used,memory.free,memory.total --format=csv
```

### âœ… éªŒè¯ä¿®å¤

è¿è¡Œè®­ç»ƒï¼Œè§‚å¯Ÿæ˜¯å¦è¿˜æœ‰ OOMï¼š
```bash
python cli/train_alphazero.py
```

å¦‚æœä»æœ‰ OOMï¼Œè¿›ä¸€æ­¥å‡å°‘ `arena_num_workers` åˆ° 1ã€‚
