# -*- coding: utf-8 -*-
"""AlphaZero è®­ç»ƒæ•™ç»ƒ - å¤šè¿›ç¨‹å¹¶è¡Œç‰ˆæœ¬"""

import warnings
warnings.filterwarnings('ignore', category=UserWarning)

import os
import time
import numpy as np
from collections import deque
from tqdm import tqdm
import torch
import torch.optim as optim
from .mcts import MCTS
from multiprocessing import Pool, cpu_count
import pickle


class Coach:
    def __init__(self, game, nnet, args):
        self.game, self.nnet, self.args = game, nnet, args
        self.train_examples_history = []
        
    def execute_episode(self, _=None):
        """å•å±€æ¸¸æˆæ‰§è¡Œ (æ”¯æŒå¤šè¿›ç¨‹è°ƒç”¨)"""
        # æ¯ä¸ªè¿›ç¨‹åˆ›å»ºè‡ªå·±çš„ MCTS
        mcts = MCTS(self.game, self.nnet, self.args)
        train_examples = []
        state, cur_player, episode_step = self.game.get_initial_state(), 0, 0
        
        while True:
            episode_step += 1
            canonical_board = self.game.get_observation(state)
            temp = int(episode_step < self.args['temp_threshold'])
            pi = mcts.get_action_prob(state, temp=temp)
            
            if episode_step <= 30:
                noise = np.random.dirichlet([self.args['dirichlet_alpha']] * len(pi))
                pi = (1 - self.args['dirichlet_epsilon']) * pi + self.args['dirichlet_epsilon'] * noise
                pi = pi * self.game.get_valid_moves(state)
                pi = pi / np.sum(pi)
            
            train_examples.append([canonical_board, cur_player, pi, None])
            action = np.random.choice(len(pi), p=pi)
            state = self.game.get_next_state(state, action)
            r = self.game.get_game_result(state, cur_player)
            
            if r != 0:
                return [(x[0], x[2], r * ((-1) ** (x[1] != cur_player))) for x in train_examples]
            
            new_player = self.game.get_current_player(state)
            if new_player != cur_player:
                cur_player = new_player
    
    def learn(self):
        """è®­ç»ƒå¾ªç¯ - æ”¯æŒå¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆ"""
        # ç¡®å®šå¹¶è¡Œè¿›ç¨‹æ•°
        num_workers = self.args.get('num_workers', min(cpu_count() - 1, 8))
        use_parallel = self.args.get('use_parallel', True) and num_workers > 1
        
        if use_parallel:
            print(f"ğŸš€ å¯ç”¨å¤šè¿›ç¨‹å¹¶è¡Œ: {num_workers} ä¸ªå·¥ä½œè¿›ç¨‹")
        
        for i in range(1, self.args['num_iterations'] + 1):
            print(f'\n{"=" * 70}')
            print(f'è¿­ä»£ {i}/{self.args["num_iterations"]}')
            print(f'{"=" * 70}')
            print(f'ğŸ“Œ å½“å‰æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.nnet.parameters())/1e6:.2f}M')
            print(f'ğŸ“Š å†å²è®­ç»ƒæ ·æœ¬: {sum(len(e) for e in self.train_examples_history)} ä¸ª')
            print()
            
            iteration_train_examples = deque([], maxlen=self.args['max_queue_length'])
            
            # ğŸ”¥ å¤šè¿›ç¨‹å¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆ
            if use_parallel:
                with Pool(processes=num_workers) as pool:
                    # ä½¿ç”¨ imap æ˜¾ç¤ºè¿›åº¦æ¡
                    results = list(tqdm(
                        pool.imap(self.execute_episode, range(self.args['num_episodes'])),
                        total=self.args['num_episodes'],
                        desc=f"å¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆ({num_workers}è¿›ç¨‹)"
                    ))
                    for result in results:
                        iteration_train_examples += result
            else:
                # å•è¿›ç¨‹æ¨¡å¼
                for _ in tqdm(range(self.args['num_episodes']), desc="è‡ªæˆ‘å¯¹å¼ˆ"):
                    iteration_train_examples += self.execute_episode()
            
            self.train_examples_history.append(iteration_train_examples)
            if len(self.train_examples_history) > self.args['num_iters_for_train_examples_history']:
                oldest = self.train_examples_history.pop(0)
                print(f"   (ä¸¢å¼ƒæœ€æ—©çš„ {len(oldest)} ä¸ªæ ·æœ¬)")
            
            train_examples = []
            for e in self.train_examples_history:
                train_examples.extend(e)
            
            print(f"\n{'â”€'*70}")
            print(f"ğŸ“¦ é˜¶æ®µ1å®Œæˆ: è‡ªæˆ‘å¯¹å¼ˆ")
            print(f"   â€¢ æœ¬æ¬¡æ”¶é›†: {len(iteration_train_examples)} ä¸ªæ–°æ ·æœ¬")
            print(f"   â€¢ å†å²ä¿ç•™: {len(self.train_examples_history)} æ¬¡è¿­ä»£çš„æ•°æ®")
            print(f"   â€¢ æ€»è®­ç»ƒé›†: {len(train_examples)} ä¸ªæ ·æœ¬")
            print(f"{'â”€'*70}\n")
            
            print(f"ğŸ§  é˜¶æ®µ2å¼€å§‹: è®­ç»ƒç¥ç»ç½‘ç»œ")
            print(f"   â€¢ è®­ç»ƒè½®æ•°: {self.args['epochs']} epochs")
            print(f"   â€¢ æ‰¹å¤§å°: {self.args['batch_size']}")
            print(f"   â€¢ ä¼˜åŒ–å™¨: Adam (lr={self.args['lr']})")
            print()
            
            self.train(train_examples)
            
            if i % self.args['checkpoint_interval'] == 0:
                self.save_checkpoint(filename=f'checkpoint_{i}.pth')
            self.save_checkpoint(filename='latest.pth')
    
    def train(self, examples):
        """è®­ç»ƒç¥ç»ç½‘ç»œ - ä¼˜åŒ–ç‰ˆ"""
        optimizer = optim.Adam(self.nnet.parameters(), lr=self.args['lr'], weight_decay=self.args['weight_decay'])
        self.nnet.train()
        
        # ğŸ”¥ é¢„å…ˆæ‰“ä¹±æ•°æ®ï¼Œé¿å…æ¯ä¸ªepoché‡å¤
        np.random.shuffle(examples)
        num_batches = len(examples) // self.args['batch_size']
        
        # ğŸ”¥ é¢„å…ˆåˆ›å»ºæ‰€æœ‰batchç´¢å¼•ï¼Œé¿å…é‡å¤è®¡ç®—
        all_indices = np.arange(len(examples))
        
        total_pi_loss = 0
        total_v_loss = 0
        
        for epoch in range(self.args['epochs']):
            # ğŸ”¥ æ¯ä¸ªepochåªæ‰“ä¹±ä¸€æ¬¡ç´¢å¼•ï¼ˆä¸æ˜¯æ•´ä¸ªæ•°æ®ï¼‰
            np.random.shuffle(all_indices)
            
            epoch_pi_loss = 0
            epoch_v_loss = 0
            
            # ğŸ”¥ æ˜¾ç¤ºepochè¿›åº¦
            epoch_start = time.time()
            
            for batch_idx in tqdm(range(num_batches), desc=f'Epoch {epoch+1}/{self.args["epochs"]}', leave=False):
                # ğŸ”¥ ä½¿ç”¨åˆ‡ç‰‡è€Œä¸æ˜¯éšæœºé‡‡æ ·ï¼Œæ›´é«˜æ•ˆ
                start_idx = batch_idx * self.args['batch_size']
                end_idx = start_idx + self.args['batch_size']
                batch_indices = all_indices[start_idx:end_idx]
                
                boards, pis, vs = list(zip(*[examples[i] for i in batch_indices]))
                
                # ğŸ”¥ ç›´æ¥è½¬æ¢ä¸ºGPU tensorï¼Œå‡å°‘CPU-GPUä¼ è¾“
                boards = torch.FloatTensor(np.array(boards))
                target_pis = torch.FloatTensor(np.array(pis))
                target_vs = torch.FloatTensor(np.array(vs))
                
                if self.args['cuda']:
                    boards, target_pis, target_vs = boards.cuda(), target_pis.cuda(), target_vs.cuda()
                
                # å‰å‘ä¼ æ’­
                out_pi, out_v = self.nnet(boards)
                l_pi = -torch.sum(target_pis * out_pi) / target_pis.size()[0]
                l_v = torch.sum((target_vs - out_v.view(-1)) ** 2) / target_vs.size()[0]
                
                total_loss = l_pi + l_v
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                total_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.nnet.parameters(), max_norm=1.0)
                optimizer.step()
                
                epoch_pi_loss += l_pi.item()
                epoch_v_loss += l_v.item()
            
            # è®¡ç®—å¹³å‡æŸå¤±
            avg_pi_loss = epoch_pi_loss / num_batches
            avg_v_loss = epoch_v_loss / num_batches
            epoch_time = time.time() - epoch_start
            
            # ğŸ”¥ æ›´ç®€æ´çš„è¾“å‡ºï¼Œæ¯10ä¸ªepochæ˜¾ç¤ºä¸€æ¬¡
            if (epoch + 1) % 10 == 0 or epoch == 0 or (epoch + 1) == self.args['epochs']:
                print(f'Epoch {epoch+1:2d}/{self.args["epochs"]}: '
                      f'Loss Ï€={avg_pi_loss:.4f} v={avg_v_loss:.4f} '
                      f'total={avg_pi_loss+avg_v_loss:.4f} '
                      f'({epoch_time:.1f}s, {num_batches/epoch_time:.1f} batch/s)')
            
            total_pi_loss += avg_pi_loss
            total_v_loss += avg_v_loss
        
        print(f"\n{'â”€'*70}")
        print(f"ğŸ“¦ é˜¶æ®µ2å®Œæˆ: ç¥ç»ç½‘ç»œè®­ç»ƒ")
        print(f"   â€¢ å¹³å‡PolicyæŸå¤±: {total_pi_loss/self.args['epochs']:.4f}")
        print(f"   â€¢ å¹³å‡ValueæŸå¤±: {total_v_loss/self.args['epochs']:.4f}")
        print(f"{'â”€'*70}\n")
    
    def save_checkpoint(self, filename='checkpoint.pth'):
        os.makedirs(self.args['checkpoint'], exist_ok=True)
        filepath = os.path.join(self.args['checkpoint'], filename)
        torch.save({'state_dict': self.nnet.state_dict()}, filepath)
        print(f'ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}')
