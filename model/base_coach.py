# -*- coding: utf-8 -*-
"""
BaseCoach - AlphaZero è®­ç»ƒåŸºç±»

è®¾è®¡ç†å¿µï¼š
1. æå– Coach å’Œ ParallelCoach çš„å…¬å…±é€»è¾‘
2. ç®€åŒ–æ¨¡å‹æ›´æ–°æœºåˆ¶ï¼ˆprevious_net vs current_netï¼‰
3. ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
"""

import os
import numpy as np
import torch
import torch.optim as optim
import torch.cuda.amp as amp
from tqdm import tqdm
from collections import deque
from abc import ABC, abstractmethod
import copy
from torch.utils.tensorboard import SummaryWriter


class BaseCoach(ABC):
    """
    AlphaZero è®­ç»ƒåŸºç±»
    
    å­ç±»éœ€è¦å®ç°ï¼š
    - execute_episode() æˆ– execute_episode_batch(): è‡ªæˆ‘å¯¹å¼ˆé€»è¾‘
    """
    
    def __init__(self, game, nnet, args):
        """
        åˆå§‹åŒ–æ•™ç»ƒ
        
        Args:
            game: æ¸¸æˆç¯å¢ƒ
            nnet: ç¥ç»ç½‘ç»œæ¨¡å‹
            args: é…ç½®å‚æ•°å­—å…¸
        """
        self.game = game
        self.nnet = nnet  # å½“å‰æ¨¡å‹ (current_net)
        self.args = args
        
        # è®­ç»ƒå†å² - ä½¿ç”¨ replay_buffer_size æˆ–é»˜è®¤ä¿ç•™ 20 æ¬¡è¿­ä»£
        # å‡è®¾æ¯æ¬¡è¿­ä»£çº¦ 18000 æ ·æœ¬ï¼Œæ ¹æ® replay_buffer_size è®¡ç®—ä¿ç•™æ¬¡æ•°
        samples_per_iter = args.get('num_self_play_games', 300) * 60  # 300å±€Ã—60æ­¥
        max_iters = max(1, args.get('replay_buffer_size', 360000) // samples_per_iter)
        
        self.train_examples_history = deque(maxlen=max_iters)
        print(f"ç»éªŒæ± : ä¿ç•™ {max_iters} æ¬¡è¿­ä»£ï¼ˆçº¦ {max_iters * samples_per_iter:,} æ ·æœ¬ï¼‰")
        
        # å‰ä¸€ä¸ªæ¨¡å‹ï¼ˆç”¨äº Arena å¯¹æˆ˜ï¼‰
        self.previous_nnet = None
        
        # TensorBoard
        self.writer = None
        if args.get('tensorboard', False):  # ä½¿ç”¨ 'tensorboard' è€Œä¸æ˜¯ 'use_tensorboard'
            log_dir = args.get('log_dir', 'results/logs')
            self.writer = SummaryWriter(log_dir=log_dir)
            print(f"âœ“ TensorBoard æ—¥å¿—ç›®å½•: {log_dir}")
        
        # åˆå§‹åŒ–æ—¶ï¼Œå°†å½“å‰æ¨¡å‹ä½œä¸º previous_net
        self._initialize_previous_net()
    
    def _initialize_previous_net(self):
        """åˆå§‹åŒ– previous_net ä¸ºå½“å‰æ¨¡å‹çš„å‰¯æœ¬"""
        # å¯¹äºæœ‰åŠ¨æ€å‚æ•°çš„æ¨¡å‹ï¼ˆå¦‚Transformerï¼‰ï¼Œç¡®ä¿åœ¨æ‹·è´å‰å·²ç»åˆå§‹åŒ–
        if hasattr(self.nnet, 'pos_embedding') and self.nnet.pos_embedding is None:
            # å¼ºåˆ¶åˆå§‹åŒ–åŠ¨æ€å‚æ•°ï¼šåšä¸€æ¬¡å‰å‘ä¼ æ’­
            with torch.no_grad():
                dummy_input = torch.randn(1, 9, 6, 6)
                if self.args.get('cuda', False):
                    dummy_input = dummy_input.cuda()
                    self.nnet.cuda()
                _ = self.nnet(dummy_input)
        
        self.previous_nnet = copy.deepcopy(self.nnet)
        # print("âœ“ åˆå§‹åŒ– previous_net = current_net")
    
    @abstractmethod
    def execute_episode(self):
        """
        æ‰§è¡Œä¸€å±€è‡ªæˆ‘å¯¹å¼ˆï¼ˆå•è¿›ç¨‹ç‰ˆæœ¬ï¼‰
        
        Returns:
            è®­ç»ƒæ ·æœ¬åˆ—è¡¨ [(observation, policy, value), ...]
        """
        pass
    
    def collect_self_play_data(self):
        """
        æ”¶é›†è‡ªæˆ‘å¯¹å¼ˆæ•°æ®
        
        æ³¨æ„ï¼šå­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•ä»¥å®ç°å¹¶è¡Œç‰ˆæœ¬
        
        Returns:
            è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        iteration_train_examples = []
        
        for _ in tqdm(range(self.args['num_episodes']), desc="è‡ªæˆ‘å¯¹å¼ˆ"):
            iteration_train_examples.extend(self.execute_episode())
        
        return iteration_train_examples
    
    def learn(self):
        """
        AlphaZero ä¸»è®­ç»ƒå¾ªç¯
        
        æµç¨‹ï¼š
        1. è‡ªæˆ‘å¯¹å¼ˆç”Ÿæˆè®­ç»ƒæ•°æ®
        2. è®­ç»ƒå½“å‰æ¨¡å‹
        3. Arena å¯¹æˆ˜ï¼ˆcurrent_net vs previous_netï¼‰
        4. æ ¹æ®èƒœç‡å†³å®šæ˜¯å¦æ›´æ–° previous_net
        5. ä¿å­˜æ£€æŸ¥ç‚¹
        """
        # åœ¨è®­ç»ƒå¼€å§‹å‰è¾“å‡º Arena æ¨¡å¼ä¿¡æ¯ï¼ˆä»…ä¸€æ¬¡ï¼‰
        arena_mode = self.args.get('arena_mode', 'serial')
        cuda_enabled = self.args.get('cuda', False)
        print(f"Arena æ¨¡å¼: {arena_mode}, CUDA: {cuda_enabled}")
        
        for iteration in range(1, self.args['num_iterations'] + 1):
            # è®¾ç½®å½“å‰è¿­ä»£å·ï¼ˆç”¨äº TensorBoard è®°å½•ï¼‰
            self._current_iteration = iteration
            
            # ä¸å•ç‹¬æ‰“å°è¿­ä»£å·ï¼Œè€Œæ˜¯åœ¨è¿›åº¦æ¡æè¿°ä¸­æ˜¾ç¤º Epoch
            # print(f'è¿­ä»£ {iteration}/{self.args["num_iterations"]}')
            
            # ========== 1. è‡ªæˆ‘å¯¹å¼ˆ ==========
            # print(f'[1/3] è‡ªæˆ‘å¯¹å¼ˆ...')
            iteration_train_examples = self.collect_self_play_data(iteration)
            
            # æ·»åŠ åˆ°å†å²
            self.train_examples_history.append(iteration_train_examples)
            
            # åˆå¹¶æ‰€æœ‰å†å²æ•°æ®
            train_examples = []
            for examples in self.train_examples_history:
                train_examples.extend(examples)
            
            # æ˜¾ç¤ºç»éªŒæ± çŠ¶æ€
            max_iters = self.train_examples_history.maxlen
            current_iters = len(self.train_examples_history)
            is_full = current_iters >= max_iters
            
            status = "âœ… å·²æ»¡" if is_full else f"â¬†ï¸ å¢é•¿ä¸­ ({current_iters}/{max_iters})"
            # print(f'  âœ“ è®­ç»ƒé›†: {len(train_examples):,} æ ·æœ¬ (ä¿ç•™ {current_iters} æ¬¡è¿­ä»£) {status}')
            
            # TensorBoard è®°å½•æ•°æ®é›†å¤§å°
            if self.writer is not None:
                self.writer.add_scalar('Data/IterationSamples', len(iteration_train_examples), iteration)
                self.writer.add_scalar('Data/TotalSamples', len(train_examples), iteration)
            
            # ========== 2. è®­ç»ƒç¥ç»ç½‘ç»œ ==========
            # print(f'[2/3] è®­ç»ƒç¥ç»ç½‘ç»œ...')
            try:
                train_stats = self.train(train_examples)
                
                # å…³é”®ï¼šè®­ç»ƒå®Œæˆåï¼Œå°†ä¸»è¿›ç¨‹çš„æ¨¡å‹ç§»åˆ° CPUï¼Œé‡Šæ”¾ GPU æ˜¾å­˜
                if self.args.get('cuda', False):
                    self.nnet.cpu()
                    import gc
                    gc.collect()
                    torch.cuda.empty_cache()
                    # print(f'  âœ“ å·²å°†æ¨¡å‹ç§»è‡³ CPUï¼Œé‡Šæ”¾ GPU æ˜¾å­˜')
            except Exception as e:
                print(f'  âŒ è®­ç»ƒå‡ºé”™: {e}')
                import traceback
                traceback.print_exc()
                continue
            
            # ========== 3. Arena å¯¹æˆ˜ ==========
            arena_interval = self.args.get('arena_interval', 1)
            # ========== 3. Arena è¯„ä¼° (æ¯ N æ¬¡è¿­ä»£) ==========
            if iteration % arena_interval == 0:
                # print(f'[3/3] Arena å¯¹æˆ˜...')
                try:
                    should_accept = self._arena_compare()
                    
                    if should_accept:
                        # print('  âœ… æ¥å—æ–°æ¨¡å‹ â†’ æ›´æ–° baseline (previous_nnet)')
                        self._accept_new_model()
                        self.save_checkpoint(filename=f'best_{iteration}.pth')
                    else:
                        # print('  âŒ æ‹’ç»æ–°æ¨¡å‹ â†’ ä¿æŒæ—§ baselineï¼Œä½†ç»§ç»­è®­ç»ƒå½“å‰æ¨¡å‹')
                        self._reject_new_model()
                
                except Exception as e:
                    print(f'  âŒ Arena å‡ºé”™: {e}')
                    import traceback
                    traceback.print_exc()
                    self._reject_new_model()
            else:
                # è·³è¿‡ Arena æ—¶ï¼Œæš‚æ—¶æ¥å—æ–°æ¨¡å‹ï¼ˆç­‰ä¸‹æ¬¡ Arena å†éªŒè¯ï¼‰
                # print(f'[3/3] è·³è¿‡ Arena (æ¯ {arena_interval} æ¬¡æ‰§è¡Œä¸€æ¬¡)')
                self._accept_new_model()
                # print('  âš ï¸  æ–°æ¨¡å‹æš‚æ—¶æ¥å—ï¼Œå°†åœ¨ä¸‹æ¬¡ Arena ä¸­éªŒè¯')
            
            # ========== 5. ä¿å­˜æ£€æŸ¥ç‚¹ ==========
            if iteration % self.args.get('checkpoint_interval', 10) == 0:
                self.save_checkpoint(filename=f'checkpoint_{iteration}.pth')
            
            self.save_checkpoint(filename='latest.pth')
    
    def _arena_compare(self):
        """
        Arena å¯¹æˆ˜ï¼šcurrent_net vs previous_net
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥æ¥å—æ–°æ¨¡å‹
        """
        from .arena import compare_models
        
        win_rate, should_accept = compare_models(
            self.game,
            self.nnet,  # current_net
            self.previous_nnet,  # previous_net
            self.args,
            current_iteration=self._current_iteration,
            total_iterations=self.args['num_iterations']
        )
        
        # TensorBoard è®°å½• Arena ç»“æœ
        if self.writer is not None and hasattr(self, '_current_iteration'):
            self.writer.add_scalar('Arena/WinRate', win_rate, self._current_iteration)
            self.writer.add_scalar('Arena/Accepted', 1 if should_accept else 0, self._current_iteration)
        
        return should_accept
    
    def _accept_new_model(self):
        """æ¥å—æ–°æ¨¡å‹ï¼šç”¨ current_net æ›´æ–° previous_net"""
        # æ·±æ‹·è´å½“å‰æ¨¡å‹åˆ° previous_nnet
        # å¯¹äºæœ‰åŠ¨æ€å‚æ•°çš„æ¨¡å‹ï¼ˆå¦‚Transformerï¼‰ï¼Œç¡®ä¿åœ¨æ‹·è´å‰å·²ç»åˆå§‹åŒ–
        if hasattr(self.nnet, 'pos_embedding') and self.nnet.pos_embedding is None:
            # å¼ºåˆ¶åˆå§‹åŒ–åŠ¨æ€å‚æ•°ï¼šåšä¸€æ¬¡å‰å‘ä¼ æ’­
            with torch.no_grad():
                dummy_input = torch.randn(1, 9, 6, 6)
                if self.args.get('cuda', False):
                    dummy_input = dummy_input.cuda()
                _ = self.nnet(dummy_input)
        
        self.previous_nnet = copy.deepcopy(self.nnet)
    
    def _reject_new_model(self):
        """
        æ‹’ç»æ–°æ¨¡å‹ï¼šä¸æ›´æ–° previous_nnetï¼Œä½†ç»§ç»­ä»å½“å‰æ¨¡å‹è®­ç»ƒ
        
        æ ¹æ® AlphaZero è®ºæ–‡ (Science 2018) å’Œ AlphaGo Zero (Nature 2017):
        "if the new player won by a margin of 55%, then it replaced the best player; 
         otherwise, it was discarded."
        
        "discarded" æ„æ€æ˜¯ï¼šä¸æ¥å—ä¸ºæ–° baselineï¼Œä½†ç»§ç»­ä»å½“å‰æ¨¡å‹è®­ç»ƒã€‚
        è¿™æ ·å…è®¸è®­ç»ƒæŒç»­æ¢ç´¢ï¼Œè€Œä¸æ˜¯å›æ»šåˆ°æ—§çŠ¶æ€ã€‚
        """
        # âœ… ä¸å›æ»šæƒé‡ - ä¿æŒ self.nnet ç»§ç»­è®­ç»ƒ
        # âœ… ä¸æ›´æ–° previous_nnet - ä¿æŒæ—§çš„ baseline
        # å·²åœ¨ Arena è¾“å‡ºä¸­æ˜¾ç¤ºå†³ç­–ï¼Œæ­¤å¤„ä¸é‡å¤è¾“å‡º
        pass
    
    def _load_temp_checkpoint(self):
        """åŠ è½½ä¸´æ—¶æ£€æŸ¥ç‚¹"""
        temp_path = os.path.join(self.args['checkpoint'], 'temp.pth')
        if os.path.exists(temp_path):
            checkpoint = torch.load(temp_path)
            self.nnet.load_state_dict(checkpoint['state_dict'])
            print(f'âœ“ å·²æ¢å¤åˆ°è®­ç»ƒå‰çš„æ¨¡å‹')
    
    def train(self, examples):
        """
        è®­ç»ƒç¥ç»ç½‘ç»œ
        
        Args:
            examples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨ [(observation, policy, value), ...]
        
        Returns:
            dict: è®­ç»ƒç»Ÿè®¡ä¿¡æ¯
        """
        # åˆ›å»ºä¼˜åŒ–å™¨
        weight_decay = self.args.get('weight_decay', 1e-4)
        if isinstance(weight_decay, str):
            weight_decay = float(weight_decay)
        
        optimizer = optim.Adam(
            self.nnet.parameters(),
            lr=self.args['lr'],
            weight_decay=weight_decay
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=self.args['epochs'],
            eta_min=self.args['lr'] * 0.01
        )
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        use_amp = self.args.get('use_amp', False) and self.args.get('cuda', False)
        scaler = amp.GradScaler(enabled=use_amp) if use_amp else None
        
        # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if self.args.get('cuda', False):
            self.nnet.cuda()
        
        self.nnet.train()
        
        pi_losses = []
        v_losses = []
        total_losses = []
        
        # ä½¿ç”¨ epoch ä½œä¸ºè¿›åº¦ï¼ˆè€Œä¸æ˜¯ batchï¼‰
        total_epochs = self.args['epochs']
        
        # åˆ›å»ºè¿›åº¦æ¡ - æ ¼å¼: (Loss=5.1234)        Train: 100%|â–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00, pi=4.0951, v=0.9491]
        # å›ºå®šå®½åº¦ç¡®ä¿ä¸SelfPlayå’ŒArenaå¯¹é½
        progress_bar = tqdm(
            total=total_epochs,
            desc='Train',
            bar_format='({postfix[0]:<15})' + '{desc}:    {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {postfix[1]}]',
            postfix=['Loss=0.0000', 'pi=0.0000, v=0.0000']
        )
        
        # è®¡ç®—æ¯ä¸ª epoch çš„æ‰¹æ¬¡æ•°
        num_batches_per_epoch = max(1, len(examples) // self.args['batch_size'])
        
        for epoch in range(self.args['epochs']):
            current_lr = optimizer.param_groups[0]['lr']
            
            # æ‰“ä¹±æ•°æ®
            np.random.shuffle(examples)
            
            epoch_pi_loss = 0
            epoch_v_loss = 0
            epoch_total_loss = 0
            
            for batch_idx in range(num_batches_per_epoch):
                try:
                    # é‡‡æ · batch
                    sample_ids = np.random.randint(len(examples), size=self.args['batch_size'])
                    boards, pis, vs = list(zip(*[examples[i] for i in sample_ids]))
                    
                    # è½¬æ¢ä¸º Tensor
                    boards = torch.FloatTensor(np.array(boards))
                    target_pis = torch.FloatTensor(np.array(pis))
                    target_vs = torch.FloatTensor(np.array(vs))
                    
                    if self.args.get('cuda', False):
                        boards = boards.cuda()
                        target_pis = target_pis.cuda()
                        target_vs = target_vs.cuda()
                    
                    # å‰å‘ä¼ æ’­
                    optimizer.zero_grad()
                    
                    if use_amp:
                        with amp.autocast(enabled=True):
                            out_pi, out_v = self.nnet(boards)
                            
                            # ç­–ç•¥æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
                            l_pi = -torch.sum(target_pis * out_pi) / target_pis.size(0)
                            
                            # ä»·å€¼æŸå¤±ï¼ˆMSEï¼‰
                            l_v = torch.sum((target_vs - out_v.view(-1)) ** 2) / target_vs.size(0)
                            
                            # æ€»æŸå¤±
                            total_loss = l_pi + l_v
                        
                        # åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
                        scaler.scale(total_loss).backward()
                        
                        # æ¢¯åº¦è£å‰ª
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(
                            self.nnet.parameters(),
                            self.args.get('grad_clip', 5.0)
                        )
                        
                        # ä¼˜åŒ–å™¨æ­¥è¿›
                        scaler.step(optimizer)
                        scaler.update()
                        
                        # ç«‹å³åˆ é™¤ä¸­é—´å˜é‡é‡Šæ”¾æ˜¾å­˜
                        del out_pi, out_v, boards, target_pis, target_vs
                    else:
                        # æ ‡å‡†è®­ç»ƒ
                        out_pi, out_v = self.nnet(boards)
                        
                        # ç­–ç•¥æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
                        l_pi = -torch.sum(target_pis * out_pi) / target_pis.size(0)
                        
                        # ä»·å€¼æŸå¤±ï¼ˆMSEï¼‰
                        l_v = torch.sum((target_vs - out_v.view(-1)) ** 2) / target_vs.size(0)
                        
                        # æ€»æŸå¤±
                        total_loss = l_pi + l_v
                        
                        # åå‘ä¼ æ’­
                        total_loss.backward()
                        
                        # æ¢¯åº¦è£å‰ª
                        torch.nn.utils.clip_grad_norm_(
                            self.nnet.parameters(),
                            self.args.get('grad_clip', 5.0)
                        )
                        
                        # ä¼˜åŒ–å™¨æ­¥è¿›
                        optimizer.step()
                        
                        # ç«‹å³åˆ é™¤ä¸­é—´å˜é‡é‡Šæ”¾æ˜¾å­˜
                        del out_pi, out_v, boards, target_pis, target_vs
                    
                    # è®°å½•æŸå¤±
                    epoch_pi_loss += l_pi.item()
                    epoch_v_loss += l_v.item()
                    epoch_total_loss += total_loss.item()
                
                except Exception as e:
                    print(f'\nâŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}')
                    import traceback
                    traceback.print_exc()
                    continue
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            # è®°å½• epoch å¹³å‡æŸå¤±
            if num_batches_per_epoch > 0:
                avg_pi_loss = epoch_pi_loss / num_batches_per_epoch
                avg_v_loss = epoch_v_loss / num_batches_per_epoch
                avg_total_loss = epoch_total_loss / num_batches_per_epoch
                
                pi_losses.append(avg_pi_loss)
                v_losses.append(avg_v_loss)
                total_losses.append(avg_total_loss)
                
                # æ›´æ–°è¿›åº¦æ¡ - æ ¼å¼: (Loss=5.1234)Train: 100%|â–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00, pi=4.0951, v=0.9491]
                progress_bar.update(1)
                progress_bar.postfix[0] = f'Loss={avg_total_loss:.4f}'
                progress_bar.postfix[1] = f'pi={avg_pi_loss:.4f}, v={avg_v_loss:.4f}'
                progress_bar.refresh()
                
                # TensorBoard è®°å½•
                if self.writer is not None:
                    global_step = epoch + 1  # éœ€è¦ä» learn() ä¼ å…¥ iteration
                    if hasattr(self, '_current_iteration'):
                        global_step = self._current_iteration * self.args['epochs'] + epoch + 1
                    self.writer.add_scalar('Loss/Policy', avg_pi_loss, global_step)
                    self.writer.add_scalar('Loss/Value', avg_v_loss, global_step)
                    self.writer.add_scalar('Loss/Total', avg_total_loss, global_step)
                    self.writer.add_scalar('Training/LearningRate', current_lr, global_step)
        
        progress_bar.close()
        
        # ä¸å†å•ç‹¬æ‰“å°æœ€ç»ˆç»Ÿè®¡ï¼Œå·²åœ¨è¿›åº¦æ¡ä¸­æ˜¾ç¤º
        
        # æ¸…ç†æ˜¾å­˜ - åˆ é™¤æ‰€æœ‰è®­ç»ƒç›¸å…³çš„å˜é‡
        del examples  # åªåˆ é™¤ examplesï¼Œä¸åˆ é™¤ä¼ å…¥çš„ train_examples
        if self.args.get('cuda', False):
            # æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€
            del optimizer, scheduler
            if scaler is not None:
                del scaler
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            # æ¸…ç©º CUDA ç¼“å­˜
            torch.cuda.empty_cache()
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.nnet.eval()
        
        # è¿”å›è®­ç»ƒç»Ÿè®¡
        return {
            'pi_losses': pi_losses,
            'v_losses': v_losses,
            'total_losses': total_losses
        }
    
    def save_checkpoint(self, filename='checkpoint.pth'):
        """
        ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
        
        Args:
            filename: æ–‡ä»¶å
        """
        checkpoint_dir = self.args.get('checkpoint', './checkpoints')
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        filepath = os.path.join(checkpoint_dir, filename)
        
        torch.save({
            'state_dict': self.nnet.state_dict(),
            'args': self.args
        }, filepath)
        
        # é™é»˜ä¿å­˜ï¼Œä¸æ‰“å°ä¿¡æ¯
        # if 'best' in filename or 'checkpoint' in filename:
        #     print(f'ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}')
    
    def load_checkpoint(self, filename='checkpoint.pth'):
        """
        åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        
        Args:
            filename: æ–‡ä»¶å
        """
        checkpoint_dir = self.args.get('checkpoint', './checkpoints')
        filepath = os.path.join(checkpoint_dir, filename)
        
        if os.path.exists(filepath):
            checkpoint = torch.load(filepath)
            self.nnet.load_state_dict(checkpoint['state_dict'])
            print(f'âœ“ å·²åŠ è½½æ¨¡å‹: {filepath}')
            return True
        else:
            print(f'âš ï¸  æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {filepath}')
            return False
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼šå…³é—­ TensorBoard writer"""
        if hasattr(self, 'writer') and self.writer is not None:
            self.writer.close()
