# -*- coding: utf-8 -*-
"""
å•è¿›ç¨‹å¹¶å‘å¤šæ¸¸æˆ + GPU æ‰¹é‡æ¨ç†
æœ€é«˜æ•ˆçš„ GPU åˆ©ç”¨æ–¹æ¡ˆ
"""

import numpy as np
import torch
import time
import math
from typing import List, Dict, Tuple


class ConcurrentGames:
    """
    å¹¶å‘æ‰§è¡Œå¤šå±€æ¸¸æˆï¼Œè‡ªåŠ¨æ‰¹é‡ GPU æ¨ç†
    
    å…³é”®ä¼˜åŠ¿ï¼š
    1. å•è¿›ç¨‹å†…å¹¶å‘å¤šå±€æ¸¸æˆï¼Œæ— è¿›ç¨‹é—´é€šä¿¡å¼€é”€
    2. è‡ªç„¶åœ°æ‰¹é‡æ”¶é›†æ¨ç†è¯·æ±‚
    3. GPU åˆ©ç”¨ç‡æœ€é«˜
    """
    
    def __init__(self, game, nnet, args):
        self.game = game
        self.nnet = nnet
        self.args = args
        self.device = next(nnet.parameters()).device
        
    def execute_episodes_concurrent(self, num_episodes):
        """
        å¹¶å‘æ‰§è¡Œå¤šå±€æ¸¸æˆ
        
        Args:
            num_episodes: æ¸¸æˆæ€»å±€æ•°
        
        Returns:
            è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        concurrent_games = min(self.args.get('parallel_games', 16), num_episodes)
        
        print(f'  ğŸš€ å¯åŠ¨å¹¶å‘ GPU è®­ç»ƒ')
        print(f'     å¹¶å‘æ¸¸æˆæ•°: {concurrent_games}')
        print(f'     MCTS æ¨¡æ‹Ÿ: {self.args["num_simulations"]}')
        print(f'     æ€»å±€æ•°: {num_episodes}')
        
        all_examples = []
        start_time = time.time()
        games_completed = 0
        
        # åˆ†æ‰¹æ‰§è¡Œ
        for batch_start in range(0, num_episodes, concurrent_games):
            batch_size = min(concurrent_games, num_episodes - batch_start)
            batch_examples = self._run_concurrent_batch(batch_size)
            all_examples.extend(batch_examples)
            games_completed += batch_size
            
            elapsed = time.time() - start_time
            speed = games_completed / elapsed if elapsed > 0 else 0
            print(f'     è¿›åº¦: {games_completed}/{num_episodes} ({speed:.1f} å±€/ç§’)')
        
        elapsed_time = time.time() - start_time
        
        print(f'  âœ… å¹¶å‘è®­ç»ƒå®Œæˆ')
        print(f'    æ€»è€—æ—¶: {elapsed_time:.2f}s')
        print(f'    å¹³å‡é€Ÿåº¦: {num_episodes / elapsed_time:.2f} å±€/ç§’')
        print(f'    æ ·æœ¬æ•°: {len(all_examples):,}')
        
        return all_examples
    
    def _run_concurrent_batch(self, num_games):
        """å¹¶å‘è¿è¡Œä¸€æ‰¹æ¸¸æˆ"""
        # åˆå§‹åŒ–æ‰€æœ‰æ¸¸æˆçŠ¶æ€
        games = []
        for i in range(num_games):
            games.append({
                'state': self.game.get_initial_state(),
                'cur_player': 0,
                'episode_step': 0,
                'examples': [],
                'mcts_trees': {},  # {state_str: {Ps, Ns, Qsa, Nsa}}
                'finished': False
            })
        
        # æ¸¸æˆä¸»å¾ªç¯
        while any(not g['finished'] for g in games):
            active_games = [g for g in games if not g['finished']]
            if not active_games:
                break
            
            # æ¯ä¸ªæ´»è·ƒæ¸¸æˆæ‰§è¡Œ MCTS
            for game_info in active_games:
                self._execute_mcts_concurrent(game_info)
                
                # è®¡ç®—åŠ¨ä½œæ¦‚ç‡
                state = game_info['state']
                s = str(state)
                trees = game_info['mcts_trees']
                
                if s not in trees or 'Nsa' not in trees[s]:
                    # åº”è¯¥ä¸ä¼šåˆ°è¿™é‡Œï¼Œä½†ä»¥é˜²ä¸‡ä¸€
                    valids = self.game.get_valid_moves(state)
                    pi = valids / np.sum(valids)
                else:
                    counts = [trees[s]['Nsa'].get(a, 0) for a in range(self.game.get_action_size())]
                    
                    temp = int(game_info['episode_step'] < self.args['temp_threshold'])
                    if temp == 0:
                        best_actions = np.where(counts == np.max(counts))[0]
                        pi = np.zeros(len(counts), dtype=np.float32)
                        pi[best_actions] = 1.0 / len(best_actions)
                    else:
                        counts_temp = np.array([x ** (1.0 / temp) for x in counts], dtype=np.float32)
                        counts_sum = float(np.sum(counts_temp))
                        if counts_sum > 0:
                            pi = counts_temp / counts_sum
                        else:
                            valids = self.game.get_valid_moves(state)
                            pi = valids / np.sum(valids)
                
                # æ·»åŠ æ¢ç´¢å™ªå£°
                if game_info['episode_step'] <= 30:
                    noise = np.random.dirichlet([self.args['dirichlet_alpha']] * len(pi))
                    pi = (1 - self.args['dirichlet_epsilon']) * pi + self.args['dirichlet_epsilon'] * noise
                    valids = self.game.get_valid_moves(state)
                    pi = pi * valids
                    if np.sum(pi) > 0:
                        pi = pi / np.sum(pi)
                    else:
                        pi = valids / np.sum(valids)
                
                # è®°å½•æ ·æœ¬
                canonical_board = self.game.get_observation(state)
                game_info['examples'].append([canonical_board, game_info['cur_player'], pi, None])
                
                # æ‰§è¡ŒåŠ¨ä½œ
                action = np.random.choice(len(pi), p=pi)
                next_state = self.game.get_next_state(state, action)
                game_info['state'] = next_state
                game_info['episode_step'] += 1
                
                # æ£€æŸ¥æ¸¸æˆæ˜¯å¦ç»“æŸ
                r = self.game.get_game_result(next_state, game_info['cur_player'])
                
                if r != 0:
                    game_info['finished'] = True
                else:
                    game_info['cur_player'] = self.game.get_current_player(next_state)
        
        # æ”¶é›†æ‰€æœ‰æ ·æœ¬
        batch_examples = []
        for game_info in games:
            if game_info['examples']:
                # è·å–æœ€ç»ˆç»“æœ
                final_state = game_info['state']
                final_player = game_info['cur_player']
                r = self.game.get_game_result(final_state, final_player)
                
                # åˆ†é…å¥–åŠ±
                final_examples = [
                    (x[0], x[2], r * ((-1) ** (x[1] != final_player)))
                    for x in game_info['examples']
                ]
                batch_examples.extend(final_examples)
        
        return batch_examples
    
    def _execute_mcts_concurrent(self, game_info):
        """ä¸ºä¸€ä¸ªæ¸¸æˆæ‰§è¡Œå®Œæ•´çš„ MCTSï¼ˆæ‰€æœ‰æ¨¡æ‹Ÿï¼‰"""
        state = game_info['state']
        trees = game_info['mcts_trees']
        
        # æ‰¹é‡å¤§å°ï¼šæ”¶é›†å¤šå°‘ä¸ªå¶å­èŠ‚ç‚¹åç«‹å³è¯„ä¼°
        eval_batch_size = self.args.get('mcts_batch_size', 32)
        pending_evaluations = []
        
        for sim_idx in range(self.args['num_simulations']):
            # æ¯æ¬¡æ¨¡æ‹Ÿä»æ ¹çŠ¶æ€å¼€å§‹
            current_state = state.clone()
            path = []
            leaf_to_evaluate = None
            
            # æœç´¢åˆ°å¶å­èŠ‚ç‚¹æˆ–ç»ˆæ­¢çŠ¶æ€
            while True:
                s = str(current_state)
                
                # ç»ˆæ­¢çŠ¶æ€ï¼šç›´æ¥å›ä¼ 
                if current_state.is_terminal():
                    returns = current_state.returns()
                    if returns[0] > returns[1]:
                        value = 1.0
                    elif returns[0] < returns[1]:
                        value = -1.0
                    else:
                        value = 0.0
                    self._backpropagate(trees, path, value)
                    break
                
                # å¶å­èŠ‚ç‚¹ï¼šéœ€è¦è¯„ä¼°
                if s not in trees or 'Ps' not in trees[s]:
                    leaf_to_evaluate = (current_state.clone(), s, path[:])
                    break
                
                # å†…éƒ¨èŠ‚ç‚¹ï¼šé€‰æ‹©åŠ¨ä½œï¼ˆUCBï¼‰
                valids = self.game.get_valid_moves(current_state)
                cur_best = -float('inf')
                best_act = -1
                
                for a in range(self.game.get_action_size()):
                    if not valids[a]:
                        continue
                    
                    if a in trees[s]['Qsa']:
                        u = trees[s]['Qsa'][a] + self.args['cpuct'] * trees[s]['Ps'][a] * \
                            math.sqrt(trees[s]['Ns']) / (1 + trees[s]['Nsa'][a])
                    else:
                        u = self.args['cpuct'] * trees[s]['Ps'][a] * math.sqrt(trees[s]['Ns'] + 1e-8)
                    
                    if u > cur_best:
                        cur_best = u
                        best_act = a
                
                if best_act == -1:
                    legal_actions = np.where(valids > 0)[0]
                    if len(legal_actions) == 0:
                        self._backpropagate(trees, path, 0.0)
                        break
                    best_act = np.random.choice(legal_actions)
                
                path.append((s, best_act))
                next_state = self.game.get_next_state(current_state, best_act)
                current_state = next_state
            
            # æ”¶é›†å¶å­èŠ‚ç‚¹ï¼Œè¾¾åˆ°æ‰¹é‡å¤§å°æ—¶ç«‹å³è¯„ä¼°
            if leaf_to_evaluate:
                pending_evaluations.append(leaf_to_evaluate)
                
                # è¾¾åˆ°æ‰¹é‡å¤§å°æˆ–æœ€åä¸€æ¬¡æ¨¡æ‹Ÿï¼Œç«‹å³è¯„ä¼°
                if len(pending_evaluations) >= eval_batch_size or sim_idx == self.args['num_simulations'] - 1:
                    self._batch_evaluate(trees, pending_evaluations)
                    pending_evaluations = []  # æ¸…ç©º
    
    def _batch_evaluate(self, trees, pending_evaluations):
        """æ‰¹é‡è¯„ä¼°æ‰€æœ‰å¾…è¯„ä¼°çš„å¶å­èŠ‚ç‚¹"""
        if not pending_evaluations:
            return
        
        # å‡†å¤‡æ‰¹é‡è¾“å…¥
        observations = []
        valid_masks = []
        
        for state, s, path in pending_evaluations:
            observations.append(self.game.get_observation(state))
            valid_masks.append(self.game.get_valid_moves(state))
        
        # GPU æ‰¹é‡æ¨ç†
        obs_tensor = torch.FloatTensor(np.array(observations)).to(self.device)
        
        self.nnet.eval()
        with torch.no_grad():
            log_pi_batch, v_batch = self.nnet(obs_tensor)
        
        pi_batch = torch.exp(log_pi_batch).cpu().numpy()
        v_batch = v_batch.cpu().numpy().flatten()
        
        # å¤„ç†ç»“æœå¹¶å›ä¼ 
        for idx, (state, s, path) in enumerate(pending_evaluations):
            pi = pi_batch[idx]
            v = float(v_batch[idx])
            valids = valid_masks[idx]
            
            # åº”ç”¨åˆæ³•åŠ¨ä½œæ©ç 
            pi = pi * valids
            if np.sum(pi) > 0:
                pi = pi / np.sum(pi)
            else:
                pi = valids / np.sum(valids)
            
            # åˆå§‹åŒ–èŠ‚ç‚¹
            if s not in trees:
                trees[s] = {'Ps': pi, 'Ns': 0, 'Qsa': {}, 'Nsa': {}}
            else:
                trees[s]['Ps'] = pi
                trees[s]['Ns'] = 0
                trees[s]['Qsa'] = {}
                trees[s]['Nsa'] = {}
            
            # å›ä¼ ä»·å€¼
            self._backpropagate(trees, path, v)
    
    def _backpropagate(self, trees, path, value):
        """å›ä¼ ä»·å€¼"""
        for s, a in reversed(path):
            if s not in trees:
                trees[s] = {'Ps': None, 'Ns': 0, 'Qsa': {}, 'Nsa': {}}
            
            if a in trees[s]['Qsa']:
                trees[s]['Qsa'][a] = (trees[s]['Nsa'][a] * trees[s]['Qsa'][a] + value) / (trees[s]['Nsa'][a] + 1)
                trees[s]['Nsa'][a] += 1
            else:
                trees[s]['Qsa'][a] = value
                trees[s]['Nsa'][a] = 1
            
            trees[s]['Ns'] += 1
            value = -value
