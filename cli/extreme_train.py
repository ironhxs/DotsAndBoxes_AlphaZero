#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""æé™GPUä¼˜åŒ– + å¤šè¿›ç¨‹å¹¶è¡Œè®­ç»ƒ"""

import warnings
import os
import sys
import multiprocessing

# è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ä¸º spawn (CUDA å…¼å®¹)
multiprocessing.set_start_method('spawn', force=True)

# ===== æŠ‘åˆ¶å¤šè¿›ç¨‹å¯¼å…¥æ—¶çš„è­¦å‘Š =====
warnings.filterwarnings('ignore', category=UserWarning, module='torch')
warnings.filterwarnings('ignore', message='pkg_resources is deprecated')
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

import torch
from model.game import DotsAndBoxesGame
from model.model import DotsAndBoxesNet
from model.coach_parallel import Coach


def extreme_train():
    """æé™ä¼˜åŒ–è®­ç»ƒ - æœ€å¤§åŒ–GPUå’ŒCPUåˆ©ç”¨ç‡"""
    
    # ğŸ”¥ å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    os.environ['OMP_NUM_THREADS'] = '4'  # OpenMP çº¿ç¨‹æ•°
    
    args = {
        # æ¸¸æˆé…ç½®
        'num_rows': 5, 'num_cols': 5,
        
        # ğŸ”¥ CPUä¼˜åŒ–: å¤šè¿›ç¨‹å¹¶è¡Œ
        'use_parallel': True,
        'num_workers': 6,  # 6ä¸ªå¹¶è¡Œè¿›ç¨‹ (æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´)
        
        # ğŸ”¥ MCTSé…ç½®: æè‡´ç²¾ç®€
        'num_simulations': 12,  # è¿›ä¸€æ­¥å‡å°‘ (15â†’12)
        'cpuct': 1.0,
        'dirichlet_alpha': 0.3,
        'dirichlet_epsilon': 0.25,
        'temp_threshold': 15,
        
        # ğŸ”¥ è®­ç»ƒè§„æ¨¡: è¶…å¤§æ•°æ®é‡
        'num_iterations': 2,
        'num_episodes': 80,  # æ›´å¤šæ¸¸æˆ (60â†’80)
        'max_queue_length': 20000,
        'num_iters_for_train_examples_history': 20,
        
        # ğŸ”¥ GPUä¼˜åŒ–: è¶…å¤§æ‰¹é‡å’Œæ·±åº¦è®­ç»ƒ
        'epochs': 100,  # å……åˆ†è®­ç»ƒï¼ˆæ•°æ®çè´µï¼Œå¤šè®­ç»ƒï¼‰
        'batch_size': 2048,  # è¶…è¶…å¤§æ‰¹é‡ (1024â†’2048)
        'lr': 0.004,  # é€‚é…å¤§batchçš„å­¦ä¹ ç‡
        'weight_decay': 1e-4,
        
        # ğŸ”¥ æ¨¡å‹é…ç½®: è¶…å¤§æ¨¡å‹
        'num_filters': 256,  # å·¨å¤§æ¨¡å‹ (128â†’256)
        'num_res_blocks': 15,  # è¶…æ·±ç½‘ç»œ (10â†’15)
        
        # å…¶ä»–
        'cuda': torch.cuda.is_available(),
        'checkpoint': './checkpoints',
        'checkpoint_interval': 1,
    }
    
    print("=" * 80)
    print("ğŸš€ğŸš€ğŸš€ æé™GPU+CPUä¼˜åŒ– - AlphaZeroç‚¹æ ¼æ£‹è®­ç»ƒ ğŸš€ğŸš€ğŸš€")
    print("=" * 80)
    print(f"ğŸ® æ¸¸æˆ: {args['num_rows']}x{args['num_cols']} ç‚¹æ ¼æ£‹")
    print(f"ğŸ”¥ GPU: {torch.cuda.get_device_name(0) if args['cuda'] else 'CPUæ¨¡å¼'}")
    print(f"ğŸ’» CPU: {args['num_workers']}è¿›ç¨‹å¹¶è¡Œ (è‡ªæˆ‘å¯¹å¼ˆåŠ é€Ÿ{args['num_workers']}x)")
    print()
    print(f"ğŸ“Š è®­ç»ƒè§„æ¨¡:")
    print(f"   â”œâ”€ è¿­ä»£æ¬¡æ•°: {args['num_iterations']}")
    print(f"   â”œâ”€ æ¯è½®æ¸¸æˆ: {args['num_episodes']}å±€")
    print(f"   â”œâ”€ MCTSæ¨¡æ‹Ÿ: {args['num_simulations']}æ¬¡/æ­¥")
    print(f"   â””â”€ é¢„è®¡æ ·æœ¬: ~{args['num_episodes'] * 30}ä¸ª/è¿­ä»£")
    print()
    print(f"ğŸ§  ç½‘ç»œæ¶æ„:")
    print(f"   â”œâ”€ é€šé“æ•°: {args['num_filters']}")
    print(f"   â”œâ”€ æ®‹å·®å±‚: {args['num_res_blocks']}")
    print(f"   â””â”€ å‚æ•°é‡: é¢„è®¡1000ä¸‡+")
    print()
    print(f"âš¡ è®­ç»ƒå¼ºåº¦:")
    print(f"   â”œâ”€ è®­ç»ƒè½®æ•°: {args['epochs']} epochs")
    print(f"   â”œâ”€ æ‰¹é‡å¤§å°: {args['batch_size']}")
    print(f"   â”œâ”€ å­¦ä¹ ç‡: {args['lr']}")
    print(f"   â””â”€ é¢„è®¡æ˜¾å­˜: 8-12 GB")
    print()
    print("=" * 80)
    print("ğŸ¯ ä¼˜åŒ–ç­–ç•¥æ€»è§ˆ:")
    print("=" * 80)
    print("âœ… CPUä¼˜åŒ–:")
    print(f"   â€¢ {args['num_workers']}è¿›ç¨‹å¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆ â†’ è‡ªæˆ‘å¯¹å¼ˆåŠ é€Ÿ{args['num_workers']}x")
    print(f"   â€¢ MCTSæ¨¡æ‹Ÿé™è‡³{args['num_simulations']}æ¬¡ â†’ å•å±€é€Ÿåº¦æå‡50%")
    print(f"   â€¢ é¢„è®¡è‡ªæˆ‘å¯¹å¼ˆæ—¶é—´: ~{args['num_episodes'] * 2.5 / args['num_workers']:.0f}ç§’")
    print()
    print("âœ… GPUä¼˜åŒ–:")
    print(f"   â€¢ è¶…å¤§æ¨¡å‹({args['num_filters']}é€šé“Ã—{args['num_res_blocks']}å±‚) â†’ æ˜¾å­˜å ç”¨8GB+")
    print(f"   â€¢ è¶…å¤§æ‰¹é‡({args['batch_size']}) â†’ GPUåˆ©ç”¨ç‡æœ€å¤§åŒ–")
    print(f"   â€¢ è¶…é•¿è®­ç»ƒ({args['epochs']}è½®) â†’ GPUæŒç»­é«˜è´Ÿè½½")
    print(f"   â€¢ é¢„è®¡GPUè®­ç»ƒæ—¶é—´: ~{args['epochs'] * 5:.0f}ç§’")
    print()
    print("âœ… æ—¶é—´åˆ†é…é¢„ä¼°:")
    est_selfplay = args['num_episodes'] * 2.5 / args['num_workers']
    est_training = args['epochs'] * 5
    total_time = est_selfplay + est_training
    print(f"   â€¢ è‡ªæˆ‘å¯¹å¼ˆ: {est_selfplay:.0f}ç§’ ({est_selfplay/total_time*100:.0f}%)")
    print(f"   â€¢ GPUè®­ç»ƒ: {est_training:.0f}ç§’ ({est_training/total_time*100:.0f}%) â† å ä¸»å¯¼")
    print(f"   â€¢ æ€»è®¡: {total_time:.0f}ç§’ = {total_time/60:.1f}åˆ†é’Ÿ/è¿­ä»£")
    print("=" * 80)
    
    # æ˜¾å­˜æ£€æŸ¥
    if args['cuda']:
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"\nğŸ“Š GPUæ˜¾å­˜: {gpu_mem:.1f} GB")
        if gpu_mem < 16:
            print("âš ï¸  è­¦å‘Š: æ˜¾å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®é™ä½ batch_size æˆ– num_filters")
            response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
            if response.lower() != 'y':
                return
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("ğŸ’¡ æç¤º: å¯åœ¨å¦ä¸€ç»ˆç«¯è¿è¡Œ './quick_monitor.sh' ç›‘æ§GPUçŠ¶æ€")
    print()
    
    game = DotsAndBoxesGame(args['num_rows'], args['num_cols'])
    nnet = DotsAndBoxesNet(game, args['num_filters'], args['num_res_blocks'])
    
    if args['cuda']:
        nnet.cuda()
    
    param_count = sum(p.numel() for p in nnet.parameters())
    print(f"âœ“ æ¨¡å‹å·²åˆ›å»º: {param_count:,} å‚æ•° ({param_count/1e6:.1f}M)")
    
    coach = Coach(game, nnet, args)
    coach.learn()
    
    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜ä½ç½®: {args['checkpoint']}/")
    print(f"ğŸ“ˆ ä¸‹ä¸€æ­¥:")
    print(f"   1. è¿è¡Œ 'python play.py' æµ‹è¯•æ¨¡å‹")
    print(f"   2. ç»§ç»­è®­ç»ƒ: ä¿®æ”¹ num_iterations åé‡æ–°è¿è¡Œ")
    print(f"   3. è¯„ä¼°æ€§èƒ½: ä½¿ç”¨ evaluate.py")


if __name__ == '__main__':
    # å¤šè¿›ç¨‹éœ€è¦
    import multiprocessing
    multiprocessing.set_start_method('spawn', force=True)
    
    extreme_train()
