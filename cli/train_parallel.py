#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¹¶è¡ŒåŒ–è®­ç»ƒè„šæœ¬ - GPU ä¼˜åŒ–ç‰ˆ

ä¸»è¦ä¼˜åŒ–ï¼š
1. æ‰¹é‡ MCTS æ¨ç†ï¼ˆbatch_size=32ï¼‰
2. å¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆï¼ˆ8 å±€åŒæ—¶è¿›è¡Œï¼‰
3. æå‡ GPU åˆ©ç”¨ç‡ï¼ˆå‡å°‘ CPU-GPU ä¼ è¾“ï¼‰

é¢„æœŸæå‡ï¼š
- GPU åˆ©ç”¨ç‡: 15% â†’ 60%+
- è®­ç»ƒé€Ÿåº¦: 2-3å€æå‡
"""

import warnings
import os
import sys
import multiprocessing
import torch
import yaml

# è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ä¸º spawn (CUDA å…¼å®¹)
multiprocessing.set_start_method('spawn', force=True)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# æŠ‘åˆ¶å¤šè¿›ç¨‹è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='torch')
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', message='pkg_resources is deprecated')
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'

from model.game import DotsAndBoxesGame
from model.model_transformer import DotsAndBoxesTransformer as DotsAndBoxesNet
from model.coach_parallel import ParallelCoach


def load_config_from_yaml(config_path='config/config.yaml'):
    """
    ä» YAML é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰é…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: å®Œæ•´çš„é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆå¹¶æ‰€æœ‰å­é…ç½®
    game_config = config['game']
    model_config = config['model']
    trainer_config = config['trainer']
    
    # æ„å»ºç»Ÿä¸€çš„ args å­—å…¸
    args = {
        # æ¸¸æˆé…ç½®
        'num_rows': game_config['num_rows'],
        'num_cols': game_config['num_cols'],
        
        # è®­ç»ƒåŸºç¡€å‚æ•°
        'num_iterations': config.get('num_iterations', trainer_config['num_iterations']),
        'num_episodes': config.get('num_self_play_games', trainer_config['num_episodes']),
        'temp_threshold': config.get('temperature_threshold', trainer_config['temp_threshold']),
        'update_threshold': trainer_config.get('update_threshold', 0.55),
        'max_queue_length': config.get('replay_buffer_size', 200000),
        'num_iters_for_train_examples_history': trainer_config.get('num_iters_for_train_examples_history', 20),
        
        # Arena å¯¹æˆ˜é…ç½®
        'arena_compare': config.get('arena_games', 40),
        'arena_interval': config.get('eval_interval', 2),
        'arena_num_workers': config.get('arena_num_workers', 8),
        'arena_random_start': True,
        'arena_mcts_simulations': config.get('arena_mcts_simulations', trainer_config['num_simulations'] * 2),
        
        # MCTS å‚æ•°
        'num_simulations': config.get('num_simulations', trainer_config['num_simulations']),
        'cpuct': config.get('cpuct', trainer_config['cpuct']),
        'dirichlet_alpha': config.get('dirichlet_alpha', trainer_config.get('dirichlet_alpha', 0.3)),
        'dirichlet_epsilon': config.get('dirichlet_epsilon', trainer_config.get('dirichlet_epsilon', 0.25)),
        
        # è®­ç»ƒå‚æ•°
        'epochs': config.get('train_epochs', trainer_config['epochs']),
        'batch_size': config.get('batch_size', trainer_config['batch_size']),
        'lr': float(config.get('learning_rate', trainer_config['lr'])),
        'weight_decay': config.get('weight_decay', 1e-4),
        'grad_clip': trainer_config.get('max_grad_norm', 5.0),
        
        # å¹¶è¡Œä¼˜åŒ–å‚æ•°
        'use_parallel': True,
        'self_play_mode': 'batch',
        'num_workers': config.get('num_parallel_games', 8),
        'mcts_batch_size': 32,
        'parallel_games': config.get('num_parallel_games', 8),
        
        # GPU é…ç½®
        'cuda': config.get('cuda', True) and torch.cuda.is_available(),
        'use_amp': config.get('use_amp', True),
        
        # æ¨¡å‹é…ç½®
        'num_filters': model_config['num_filters'],
        'num_res_blocks': model_config['num_blocks'],
        'num_heads': model_config['num_heads'],
        
        # æ£€æŸ¥ç‚¹
        'checkpoint': './results/checkpoints',
        'checkpoint_interval': config.get('checkpoint_interval', 10),
    }
    
    return args, config


def main():
    # GPUä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    os.environ['OMP_NUM_THREADS'] = '4'
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"âœ“ CUDA å¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"âœ“ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\n")
    else:
        print("âš ï¸  è­¦å‘Š: CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒ\n")
    
    # ========== ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰å‚æ•° ==========
    args, raw_config = load_config_from_yaml('config/config.yaml')
    
    print("="*60)
    print("  AlphaZero å¹¶è¡Œè®­ç»ƒ - é…ç½®é©±åŠ¨ç‰ˆ")
    print("="*60)
    
    # åˆå§‹åŒ–æ¸¸æˆ
    print(f"\næ¸¸æˆ: {args['num_rows']}x{args['num_cols']} Dots and Boxes")
    
    game = DotsAndBoxesGame(
        num_rows=args['num_rows'],
        num_cols=args['num_cols']
    )
    
    obs_shape = game.get_observation(game.get_initial_state()).shape
    print(f"åŠ¨ä½œç©ºé—´: {game.get_action_size()}")
    print(f"è§‚å¯Ÿå½¢çŠ¶: {obs_shape}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    device = torch.device('cuda' if args['cuda'] else 'cpu')
    print(f"\nè®¾å¤‡: {device}")
    
    if device.type == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    nnet = DotsAndBoxesNet(
        game=game,
        num_blocks=args['num_res_blocks'],
        num_filters=args['num_filters'],
        num_heads=args['num_heads']
    ).to(device)
    
    total_params = sum(p.numel() for p in nnet.parameters())
    print(f"æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
    
    # æ‰“å°è®­ç»ƒé…ç½®
    print("\n" + "=" * 80)
    print("ğŸ§  AlphaZero å¹¶è¡Œè®­ç»ƒç³»ç»Ÿ - é…ç½®é©±åŠ¨ç‰ˆ")
    print("=" * 80)
    print(f"è®­ç»ƒè¿­ä»£: {args['num_iterations']} æ¬¡")
    print(f"æ¯æ¬¡è¿­ä»£: {args['num_episodes']} å±€è‡ªæˆ‘å¯¹å¼ˆ")
    print(f"ArenaéªŒè¯: æ¯ {args['arena_interval']} æ¬¡è¿­ä»£ ({args['arena_compare']} å±€)")
    print(f"æ›´æ–°é˜ˆå€¼: {args['update_threshold']*100}% èƒœç‡")
    print(f"\nâš™ï¸  è‡ªæˆ‘å¯¹å¼ˆ: {args['num_workers']} CPUè¿›ç¨‹ | MCTS={args['num_simulations']}æ¬¡")
    print(f"âš™ï¸  Arenaå¯¹æˆ˜: {args['arena_num_workers']} CPUè¿›ç¨‹ | MCTS={args['arena_mcts_simulations']}æ¬¡")
    print(f"\nâœ¨ å¹¶è¡Œä¼˜åŒ–:")
    print(f"  MCTS æ‰¹é‡å¤§å°: {args['mcts_batch_size']}")
    print(f"  å¹¶è¡Œæ¸¸æˆæ•°: {args['parallel_games']}")
    print(f"  é¢„æœŸ GPU åˆ©ç”¨ç‡æå‡: 3-4å€")
    print(f"\nç¥ç»ç½‘ç»œ: Transformer + ConvNeXt ({args['num_filters']}d Ã— {args['num_res_blocks']} blocks)")
    print(f"æ³¨æ„åŠ›æœºåˆ¶: {args['num_heads']}-head Self-Attention")
    print(f"è®­ç»ƒè§„æ¨¡: Batch={args['batch_size']}, Epochs={args['epochs']}, LR={args['lr']}")
    print(f"GPUåŠ é€Ÿ: {'âœ… CUDAå¯ç”¨ + AMP' if args['cuda'] else 'âŒ ä»…CPU'}")
    print("=" * 80)
    
    # æ£€æŸ¥ç‚¹ç›®å½•
    os.makedirs(args['checkpoint'], exist_ok=True)
    
    # åˆå§‹åŒ–å¹¶è¡Œ Coach
    coach = ParallelCoach(game, nnet, args)
    
    # å¼€å§‹è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹ AlphaZero å¹¶è¡Œè®­ç»ƒ...")
    print("   æ¯æ¬¡è¿­ä»£åŒ…å«: å¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆ â†’ æ‰¹é‡è®­ç»ƒ â†’ Arenaå¯¹æˆ˜ â†’ æ¨¡å‹ç­›é€‰\n")
    
    try:
        coach.learn()
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        coach.save_checkpoint(filename='interrupted.pth')
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ° {args['checkpoint']}/interrupted.pth")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        coach.save_checkpoint(filename='error.pth')
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ° {args['checkpoint']}/error.pth")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {args['checkpoint']}/best_*.pth")
    print(f"æœ€æ–°æ¨¡å‹ä¿å­˜åœ¨: {args['checkpoint']}/latest.pth")
    print("\nä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éªŒè¯æ¨¡å‹:")
    print(f"  python cli/play_ultimate.py --checkpoint {args['checkpoint']}/best_*.pth")
    print(f"  python cli/evaluate_model.py --checkpoint {args['checkpoint']}/best_*.pth")
    print("=" * 80)


if __name__ == '__main__':
    # å¿…é¡»åœ¨ä¸»å—ä¸­å†æ¬¡è®¾ç½® (ç¡®ä¿ç”Ÿæ•ˆ)
    multiprocessing.set_start_method('spawn', force=True)
    main()
