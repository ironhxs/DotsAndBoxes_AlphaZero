#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¹¶è¡ŒåŒ–è®­ç»ƒè„šæœ¬ - GPU ä¼˜åŒ–ç‰ˆ

ä¸»è¦ä¼˜åŒ–ï¼š
1. æ‰¹é‡ MCTS æ¨ç†ï¼ˆbatch_size=32ï¼‰
2. å¹¶è¡Œè‡ªæˆ‘å¯¹å¼ˆï¼ˆ8 å±€åŒæ—¶è¿›è¡Œï¼‰
3. æå‡ GPU åˆ©ç”¨ç‡ï¼ˆå‡å°‘ CPU-GPU ä¼ è¾“ï¼‰

é¢„æœŸæå‡ï¼š
- GPU åˆ©ç”¨ç‡: 15% â†’ 60%+
- è®­ç»ƒé€Ÿåº¦: 2-3å€æå‡
"""

import warnings
import os
import sys
import multiprocessing
import torch
import yaml

# è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ä¸º spawn (CUDA å…¼å®¹)
multiprocessing.set_start_method('spawn', force=True)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# æŠ‘åˆ¶å¤šè¿›ç¨‹è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='torch')
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', message='pkg_resources is deprecated')
os.environ['PYTHONWARNINGS'] = 'ignore::UserWarning'

from model.game import DotsAndBoxesGame
from model.model_transformer import DotsAndBoxesTransformer as DotsAndBoxesNet
from model.coach_parallel import ParallelCoach


def load_config_from_yaml(config_path='config/config.yaml'):
    """
    ä» YAML é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰é…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: å®Œæ•´çš„é…ç½®å­—å…¸
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æ‰‹åŠ¨åŠ è½½å­é…ç½®æ–‡ä»¶ï¼ˆæ”¯æŒ Hydra defaults ç»“æ„ï¼‰
    config_dir = os.path.dirname(config_path)
    
    # ä» defaults ä¸­æå–å­é…ç½®åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    defaults = config.get('defaults', [])
    game_name = 'dots_and_boxes'
    model_name = 'transformer'
    trainer_name = 'alphazero'
    
    for item in defaults:
        if isinstance(item, dict):
            if 'game' in item:
                game_name = item['game']
            elif 'model' in item:
                model_name = item['model']
            elif 'trainer' in item:
                trainer_name = item['trainer']
    
    # åŠ è½½å­é…ç½®æ–‡ä»¶
    with open(os.path.join(config_dir, 'game', f'{game_name}.yaml'), 'r', encoding='utf-8') as f:
        game_config = yaml.safe_load(f)
    
    with open(os.path.join(config_dir, 'model', f'{model_name}.yaml'), 'r', encoding='utf-8') as f:
        model_config = yaml.safe_load(f)
    
    with open(os.path.join(config_dir, 'trainer', f'{trainer_name}.yaml'), 'r', encoding='utf-8') as f:
        trainer_config = yaml.safe_load(f)
    
    # æ„å»ºç»Ÿä¸€çš„ args å­—å…¸
    args = {
        # æ¸¸æˆé…ç½®
        'num_rows': game_config['num_rows'],
        'num_cols': game_config['num_cols'],
        
        # è®­ç»ƒåŸºç¡€å‚æ•°
        'num_iterations': config.get('num_iterations', trainer_config['num_iterations']),
        'num_episodes': config.get('num_self_play_games', trainer_config['num_episodes']),
        'temp_threshold': config.get('temperature_threshold', trainer_config['temp_threshold']),
        'update_threshold': trainer_config.get('update_threshold', 0.55),
        'max_queue_length': config.get('replay_buffer_size', 200000),
        'num_iters_for_train_examples_history': trainer_config.get('num_iters_for_train_examples_history', 20),
        
        # Arena é…ç½®
        'arena_compare': config.get('arena_compare', 40),
        'arena_num_workers': config.get('arena_num_workers', 8),
        'arena_random_start': True,
        'arena_mcts_simulations': config.get('arena_mcts_simulations', trainer_config['num_simulations'] * 2),
        'arena_mode': config.get('arena_mode', 'serial'),  # æ·»åŠ  arena_mode é…ç½®
        'update_threshold': config.get('update_threshold', config.get('arena_threshold', 0.55)),
        
        # MCTS å‚æ•°
        'num_simulations': config.get('num_simulations', trainer_config['num_simulations']),
        'cpuct': config.get('cpuct', trainer_config['cpuct']),
        'dirichlet_alpha': config.get('dirichlet_alpha', trainer_config.get('dirichlet_alpha', 0.3)),
        'dirichlet_epsilon': config.get('dirichlet_epsilon', trainer_config.get('dirichlet_epsilon', 0.25)),
        
        # è®­ç»ƒå‚æ•°
        'epochs': config.get('train_epochs', trainer_config['epochs']),
        'batch_size': config.get('batch_size', trainer_config['batch_size']),
        'lr': float(config.get('learning_rate', trainer_config['lr'])),
        'weight_decay': config.get('weight_decay', 1e-4),
        'grad_clip': trainer_config.get('max_grad_norm', 5.0),
        
        # å¹¶è¡Œä¼˜åŒ–å‚æ•°
        'use_parallel': True,
        'parallel_mode': config.get('parallel_mode', 'full'),
        'use_multiprocess': config.get('use_multiprocess', True),
        'self_play_mode': 'batch',
        'num_workers': config.get('num_parallel_games', 8),
        'mcts_batch_size': config.get('mcts_batch_size', 32),
        'parallel_games': config.get('num_parallel_games', 8),
        'use_gpu_inference': config.get('use_gpu_inference', True),
        
        # GPU é…ç½®
        'cuda': config.get('cuda', True) and torch.cuda.is_available(),
        'use_amp': config.get('use_amp', True),
        
        # æ¨¡å‹é…ç½®
        'num_filters': model_config['num_filters'],
        'num_res_blocks': model_config['num_blocks'],
        'num_heads': model_config['num_heads'],
        
        # æ£€æŸ¥ç‚¹
        'checkpoint': './results/checkpoints',
        'checkpoint_interval': config.get('checkpoint_interval', 10),
    }
    
    return args, config


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®
    args, config = load_config_from_yaml()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if args['cuda'] and torch.cuda.is_available() else 'cpu')
    args['device'] = device
    
    # ç®€æ´çš„è®¾å¤‡ä¿¡æ¯
    if args['cuda'] and torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_properties(0).name
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"âœ“ GPU: {gpu_name} ({gpu_mem:.0f}GB)")
    else:
        print("âš  ä½¿ç”¨CPUè®­ç»ƒ")
    
    # åˆå§‹åŒ–æ¸¸æˆå’Œæ¨¡å‹
    game = DotsAndBoxesGame(**{'num_rows': args['num_rows'], 'num_cols': args['num_cols']})
    
    nnet = DotsAndBoxesNet(
        game=game,
        num_blocks=args['num_res_blocks'],
        num_filters=args['num_filters'],
        num_heads=args['num_heads']
    ).to(device)
    
    total_params = sum(p.numel() for p in nnet.parameters())
    print(f"æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
    
    # æ‰“å°ç®€æ´çš„é…ç½®ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ğŸš€ AlphaZero è®­ç»ƒ")
    print("=" * 70)
    print(f"è¿­ä»£: {args['num_iterations']} | è‡ªæˆ‘å¯¹å¼ˆ: {args['num_episodes']}å±€/æ¬¡ | MCTS: {args['num_simulations']}æ¬¡")
    print(f"è®­ç»ƒ: Batch={args['batch_size']}, Epochs={args['epochs']}, LR={args['lr']}")
    print(f"æ¨¡å‹: {args['num_filters']}dÃ—{args['num_res_blocks']}å— | å‚æ•°: {total_params/1e6:.1f}M")
    print(f"å¹¶è¡Œ: {args['num_workers']} workers | GPUæ‰¹é‡: {args['mcts_batch_size']}")
    print("=" * 70)
    
    # æ£€æŸ¥ç‚¹ç›®å½•
    os.makedirs(args['checkpoint'], exist_ok=True)
    
    # åˆå§‹åŒ–å¹¶è¡Œ Coach
    coach = ParallelCoach(game, nnet, args)
    
    # å¼€å§‹è®­ç»ƒ
    print("\n")
    
    try:
        coach.learn()
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        coach.save_checkpoint(filename='interrupted.pth')
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ° {args['checkpoint']}/interrupted.pth")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        coach.save_checkpoint(filename='error.pth')
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ° {args['checkpoint']}/error.pth")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {args['checkpoint']}/best_*.pth")
    print(f"æœ€æ–°æ¨¡å‹ä¿å­˜åœ¨: {args['checkpoint']}/latest.pth")
    print("\nä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éªŒè¯æ¨¡å‹:")
    print(f"  python cli/play_ultimate.py --checkpoint {args['checkpoint']}/best_*.pth")
    print(f"  python cli/evaluate_model.py --checkpoint {args['checkpoint']}/best_*.pth")
    print("=" * 80)


if __name__ == '__main__':
    # å¿…é¡»åœ¨ä¸»å—ä¸­å†æ¬¡è®¾ç½® (ç¡®ä¿ç”Ÿæ•ˆ)
    multiprocessing.set_start_method('spawn', force=True)
    main()
